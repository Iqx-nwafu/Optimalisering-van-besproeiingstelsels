"""
Deep Neural Network approach for multi‑objective irrigation grouping optimization.

This script implements a simple feed‑forward neural network using only NumPy.  The
network learns to predict a ranking score for each irrigation lateral based on
its static features.  A low predicted score means the lateral should be
selected earlier in the grouping order.  After training, laterals are sorted
according to the network’s output to form the final schedule.

The training data is generated by sampling random permutations of all
laterals, evaluating each permutation with the ``IrrigationGroupingEnv``
environment, and computing objective values.  The objectives we care about
are (1) the variance of the minimum hydraulic margin across groups and (2)
the minimum margin achieved over the entire episode.  The
``evaluate_permutation`` function runs a complete episode given a candidate
ordering and returns these objective values.  Using the objective values we
select the best sampled permutations and derive target positions for each
lateral.  Each target position is normalised between 0 and 1 (0 means
earliest, 1 means latest) and used as a label for training the neural network.

Because purely supervised labels for combinatorial optimisation are rarely
available, this approach follows the idea that reinforcement learning or
heuristic search can produce better heuristics than static labelling【388808472836725†L31-L69】.  Here
we use random sampling as a proxy for search.  The concept of using neural
networks and reinforcement learning to tackle combinatorial problems was
popularised by neural combinatorial optimisation approaches, where a neural
network is trained with policy gradient to produce permutations【388808472836725†L31-L69】.

Usage
-----
1. Ensure that the ``tree_evaluator.py`` module is available on your Python
   path and that the ``Nodes.xlsx`` and ``Pipes.xlsx`` files reside in the
   working directory.  These provide the hydraulic network structure.
2. Run this script.  Training parameters such as the number of random
   permutations, top‑k selection, learning rate and number of epochs can be
   adjusted in the ``main`` function.
3. The script prints the final predicted ordering and objective values.

Notes
-----
This implementation relies exclusively on NumPy and does not require PyTorch
or TensorFlow.  It is intended as a starting point for comparison with PPO
and NSGA‑II.  The neural network here is very simple and may need to be
extended (e.g. adding more layers) to achieve competitive performance.
"""

from __future__ import annotations

import numpy as np
from typing import List, Tuple, Dict, Optional

try:
    # Import the evaluation environment from the existing project.  If this
    # fails because ``tree_evaluator.py`` is unavailable, please ensure that
    # module is installed on your PYTHONPATH.
    from ppo_env import IrrigationGroupingEnv
    from tree_evaluator import (
        TreeHydraulicEvaluator,
        load_nodes_xlsx,
        load_pipes_xlsx,
        build_lateral_ids_for_field_nodes,
        is_field_node_id,
    )
except ImportError as e:
    raise ImportError(
        "Required modules not found. Make sure `ppo_env.py` and `tree_evaluator.py` "
        "are accessible in the PYTHONPATH."
    ) from e


class SimpleNN:
    """A minimal two‑layer neural network implemented with NumPy.

    The network maps static feature vectors of shape (F,) to a scalar score.  A
    smaller score indicates that the lateral should be selected earlier.  The
    model consists of one hidden layer with a tanh activation followed by a
    linear output layer.  Mean squared error is used as the loss function.
    """

    def __init__(self, input_dim: int, hidden_dim: int = 32, lr: float = 1e-3, seed: Optional[int] = None) -> None:
        rng = np.random.default_rng(seed)
        # Xavier/Glorot initialisation for weights
        self.W1 = rng.normal(0, np.sqrt(2.0 / (input_dim + hidden_dim)), size=(input_dim, hidden_dim))
        self.b1 = np.zeros(hidden_dim, dtype=np.float64)
        self.W2 = rng.normal(0, np.sqrt(2.0 / (hidden_dim + 1)), size=(hidden_dim, 1))
        self.b2 = np.zeros(1, dtype=np.float64)
        self.lr = lr

    def forward(self, X: np.ndarray) -> Tuple[np.ndarray, Tuple[np.ndarray, np.ndarray, np.ndarray]]:
        """Forward pass through the network.

        Parameters
        ----------
        X : np.ndarray
            Input features of shape (N, F).

        Returns
        -------
        out : np.ndarray
            Output scores of shape (N,), squeezed from (N,1).
        cache : tuple
            Cached values for the backward pass.
        """
        z1 = X @ self.W1 + self.b1  # (N, hidden_dim)
        a1 = np.tanh(z1)            # (N, hidden_dim)
        z2 = a1 @ self.W2 + self.b2  # (N, 1)
        out = z2.squeeze()          # (N,)
        return out, (X, z1, a1)

    def backward(self, out: np.ndarray, y: np.ndarray, cache: Tuple[np.ndarray, np.ndarray, np.ndarray]) -> None:
        """Backward pass computing gradients and updating the parameters.

        Parameters
        ----------
        out : np.ndarray
            Predicted outputs of shape (N,).
        y : np.ndarray
            Target outputs of shape (N,).
        cache : tuple
            Cached values from the forward pass.
        """
        X, z1, a1 = cache
        N = X.shape[0]
        # Compute gradient of mean squared error loss: dL/dout = 2 * (out - y) / N
        dloss = (out - y) * (2.0 / N)  # (N,)
        # Gradients for the output layer
        dW2 = a1.T @ dloss.reshape(-1, 1)  # (hidden_dim, 1)
        db2 = np.sum(dloss)               # scalar
        # Propagate to hidden layer
        da1 = dloss.reshape(-1, 1) @ self.W2.T  # (N, hidden_dim)
        dz1 = da1 * (1.0 - np.tanh(z1) ** 2)    # derivative of tanh
        # Gradients for the first layer
        dW1 = X.T @ dz1                    # (input_dim, hidden_dim)
        db1 = np.sum(dz1, axis=0)          # (hidden_dim,)
        # Update parameters
        self.W2 -= self.lr * dW2
        self.b2 -= self.lr * db2
        self.W1 -= self.lr * dW1
        self.b1 -= self.lr * db1

    def fit(self, X: np.ndarray, y: np.ndarray, epochs: int = 100, verbose: bool = True) -> None:
        """Train the network using gradient descent.

        Parameters
        ----------
        X : np.ndarray
            Input features of shape (N, F).
        y : np.ndarray
            Target outputs of shape (N,).
        epochs : int
            Number of training epochs.
        verbose : bool
            Whether to print progress messages.
        """
        for epoch in range(epochs):
            out, cache = self.forward(X)
            loss = np.mean((out - y) ** 2)
            self.backward(out, y, cache)
            if verbose and (epoch + 1) % max(1, epochs // 10) == 0:
                print(f"Epoch {epoch + 1}/{epochs}, loss={loss:.6f}")

    def predict(self, X: np.ndarray) -> np.ndarray:
        """Compute the network output for input features.

        Parameters
        ----------
        X : np.ndarray
            Input features of shape (N, F).

        Returns
        -------
        np.ndarray
            Scores of shape (N,).
        """
        out, _ = self.forward(X)
        return out


def evaluate_permutation(env: IrrigationGroupingEnv, order: np.ndarray) -> Tuple[float, float]:
    """Evaluate a complete irrigation schedule using the environment.

    Parameters
    ----------
    env : IrrigationGroupingEnv
        Instance of the environment configured with the hydraulic evaluator and
        lateral mapping.
    order : np.ndarray
        Sequence of indices representing the order in which laterals are opened.

    Returns
    -------
    tuple(float, float)
        (final_variance, negative_min_margin).  ``final_variance`` is the
        variance of the minimum margins across groups at the end of the episode,
        and ``negative_min_margin`` is the negative of the smallest margin
        achieved during the episode (so that both objectives are minimised in
        optimisation).
    """
    obs, _ = env.reset()
    done = False
    final_var = None
    min_margin_neg = None
    for act in order:
        obs, reward, done, truncated, info = env.step(int(act))
        if done:
            # At termination the info dict contains final statistics
            final_var = info.get("final_var", info.get("running_var"))
            min_margin_neg = -info.get("min_s_over_episode", 0.0)
            break
    if final_var is None:
        # Episode finished without hard violation
        final_var = info.get("final_var", info.get("running_var"))
        min_margin_neg = -info.get("min_s_over_episode", 0.0)
    return float(final_var), float(min_margin_neg)


def generate_training_data(
    env: IrrigationGroupingEnv,
    num_samples: int = 200,
    top_k: int = 10,
    seed: Optional[int] = None,
) -> Tuple[np.ndarray, np.ndarray]:
    """Generate training data by sampling random schedules.

    Randomly samples ``num_samples`` permutations of all laterals, evaluates each
    with the environment and selects the top ``top_k`` permutations based on a
    composite objective.  For each of the selected permutations, this function
    records the (lateral features, position) pairs which are used as training
    examples for the neural network.

    Parameters
    ----------
    env : IrrigationGroupingEnv
        Environment instance.
    num_samples : int
        Number of random permutations to generate.
    top_k : int
        Number of best permutations (lowest composite objective) to use for
        training.
    seed : Optional[int]
        Random seed for reproducibility.

    Returns
    -------
    X_train : np.ndarray
        Feature matrix of shape (top_k * N, F) where N is the number of
        laterals and F is the feature dimension.
    y_train : np.ndarray
        Target positions of shape (top_k * N,), normalised to [0,1].
    """
    rng = np.random.default_rng(seed)
    N = env.N
    # Use the static features from the environment as the input feature matrix
    X_static = env._feat_static.copy().astype(np.float64)
    samples: List[Tuple[np.ndarray, Tuple[float, float]]] = []
    for i in range(num_samples):
        perm = rng.permutation(N)
        var, neg_min = evaluate_permutation(env, perm)
        # Composite objective: prioritise low variance and high min margin
        obj = var + neg_min
        samples.append((perm, (var, neg_min, obj)))
    # Sort by composite objective (lower is better)
    samples.sort(key=lambda x: x[1][2])
    # Select top_k
    top_samples = samples[:top_k]
    # Prepare training data
    X_list = []
    y_list = []
    for perm, (var, neg_min, obj) in top_samples:
        # For each position in the permutation, create a training example
        for pos, idx in enumerate(perm):
            X_list.append(X_static[idx])
            y_list.append(pos / float(N - 1))
    X_train = np.stack(X_list, axis=0)
    y_train = np.array(y_list, dtype=np.float64)
    return X_train, y_train


def build_environment(seed: int = 0) -> IrrigationGroupingEnv:
    """Instantiate the irrigation grouping environment with real network data.

    Loads the nodes and pipes Excel files using ``tree_evaluator.py``, builds
    the lateral list and mapping, computes single lateral margins, and creates
    an ``IrrigationGroupingEnv`` instance.  Adjust the hyperparameters here
    (such as beta_infeasible, alpha_var_final and lambda_branch_soft) to match
    the PPO training setup used for comparison.

    Parameters
    ----------
    seed : int
        Random seed for reproducibility.

    Returns
    -------
    IrrigationGroupingEnv
        Configured environment ready for sampling and evaluation.
    """
    nodes = load_nodes_xlsx("Nodes.xlsx")
    edges = load_pipes_xlsx("Pipes.xlsx")
    evaluator = TreeHydraulicEvaluator(nodes=nodes, edges=edges, root="J0", H0=25.0, Hmin=11.59)
    field_nodes = [nid for nid in nodes.keys() if is_field_node_id(nid)]
    lateral_ids, lateral_to_node = build_lateral_ids_for_field_nodes(field_nodes)
    # Optionally compute single lateral margins
    single_margin_map: Dict[str, float] = {}
    for lid in lateral_ids:
        r = evaluator.evaluate_group([lid], lateral_to_node=lateral_to_node, q_lateral=0.012)
        single_margin_map[lid] = float(r.min_margin)
    env = IrrigationGroupingEnv(
        evaluator=evaluator,
        lateral_ids=lateral_ids,
        lateral_to_node=lateral_to_node,
        single_margin_map=single_margin_map,
        beta_infeasible=1e4,
        alpha_var_final=0.0,
        lambda_branch_soft=0.1,
        seed=seed,
    )
    return env


def main() -> None:
    """Run the DNN training and evaluate the resulting schedule."""
    # Build environment
    env = build_environment(seed=0)
    print(f"Loaded environment with {env.N} laterals and {env.F_static} static features.")
    # Generate training data
    X_train, y_train = generate_training_data(env, num_samples=200, top_k=10, seed=0)
    print(f"Generated training dataset of {X_train.shape[0]} samples.")
    # Train neural network
    model = SimpleNN(input_dim=X_train.shape[1], hidden_dim=32, lr=1e-2, seed=0)
    model.fit(X_train, y_train, epochs=200, verbose=True)
    # Use model to predict ordering
    scores = model.predict(env._feat_static.astype(np.float64))
    # Lower scores should be selected earlier
    predicted_order = np.argsort(scores)
    # Evaluate predicted schedule
    final_var, neg_min_margin = evaluate_permutation(env, predicted_order)
    print("Predicted schedule results:")
    print(f"  Final variance: {final_var:.6f}")
    print(f"  Minimum margin: {-neg_min_margin:.6f}")
    # Optionally, print the predicted ordering and corresponding lateral IDs
    predicted_lids = [env.lateral_ids[i] for i in predicted_order]
    print("Predicted lateral ordering:")
    print(predicted_lids)


if __name__ == "__main__":
    main()